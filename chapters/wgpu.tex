\chapter{WGpu}
WGpu is a safe rendering library designed to work with different backends, like Vulkan, OpenGL, DX11, DX12, Metal and WebGpu. Its api is inspired by the WebGpu one, that share some concepts with Vulkan, but it is more simplified. For this project, the version 0.9 has been used, and at that version, WGpu is rely on Gfx, an internal rendering library that actually manage the compilation over different backends.
\begin{center}
	\includegraphics[width=0.9\textwidth]{wgpu_anatomy.png}
	\captionof{figure}{WGpu anatomy}
\end{center}

The project require some features that was missing in Gfx (and so in WGpu):
\begin{itemize}
	\item Direct display: allow to draw directly on the screen without any windowing system running (the project would be the windowing system).
	\item External memory: allow to digest memory resources generated by other programs (like the Wayland clients) and transform them into a rendering resource without copying its content. This is fundamental to build an efficient compositor.
\end{itemize}
Both features have been developed and upstreamed to the Gfx project. These features works only with the Vulkan backend because other rendering backends miss required functionalities. Then such function have been exposed in WGpu to make them accessible for the "WGpu Engine".

\subsection{API}
\begin{center}
	\includegraphics[width=0.9\textwidth]{wgpu_api_anatomy.png}
	\captionof{figure}{WGpu API anatomy}
\end{center}

\section{Vulkan}
Vulkan is a low level, high performance and concurrenct graphic api, successor of OpenGL that allow a direct control of the hardware.
One of the main difference compared to its predecessor, OpenGL, is that Vulkan tends to delegate some of the tasks generally handled by the driver to the user. This choice is made to reduce the effort required by the drivers to predict how resources are going to be used and, combined with a much more verbose api, allow the driver to be much smaller and efficient (in fact Vulkan driver are called thin drivers). Even if this project do not use Vulkan directly, it was required to implement the required features in WGpu.
\begin{center}
	\includegraphics[width=0.9\textwidth]{vulkan_api_anatomy.png}
	\captionof{figure}{Vulkan API anatomy}
\end{center}


\section{Direct display}
Presenting something on screen is not an easy task and require the usage of specialized apis. The fbdev driver has been deprecated long time ago in favor of the drm/kms system. This system allow to present rectangular surfaces on the screen in any order while taking advantage of hardware compositing, if possible. Unfortunately it does not have rendering capability, so the Drm/Kms system is used to create and present a surface while a different rendering api to draw on. The interaction of multiple apis increase the complexity and lead to potential bugs, so for this project, an alternative way as been employed: by using VK\_KHR\_display and related Vulkan extensions is possible to take the control of available monitors to render on. So these extensions allow Vulkan to draw and present without requiring any other api interaction. Still, it rely on some Drm/Kms concepts, so, even if simplified, they are required to be known.
\begin{itemize}
	\item \textbf{Framebuffer}: A framebuffer is a representation of a generic device buffer.
	\item \textbf{Plane}: A dedicated memory object at which is possible to dynamically attach a framebuffer. A device can expose multiple planes to take advantage of hardware accelerated compositing.
	\item \textbf{CRTC}: A scanout engine responsible to push the pixel of on a plane throught a connector.
	\item \textbf{Connector}: Represent a physical display connector, like HDMI, VGA and DisplayPort.
	\item \textbf{Encoder}: An entity that encode data sent by the crtc into a format a connector can understand.
\end{itemize}


\section{External memory}
Memory is shared between clients and server mainly using two ways:
\begin{itemize}
	\item Using the wl\_shm and wl\_shm\_pool interfaces: these interfaces allow clients to share a mmap-able fd with the server.
	\item Using the unstable zwp\_linux\_dmabuf\_v1 and zwp\_linux\_buffer\_params\_v1 interfaces: these interfaces allow clients to share a dma buffer with the server. 
\end{itemize}
These interfaces are used by the clients to share surfaces content with the server, so the rendering api used by the server need to elaborate them in some ways. Even if it is possible to just copy the surface content at each presentation into something the rendering api can understand, it is not recommended due to the generated overhead that will lead into performance penalties.
Vulkan has the ability to directly import both mmap-able fds and dma buffers, so that no data copy will be involved. Part of the project involve the integration of the required Vulkan extensions into the used rendering api. 
More specifically, the required Vulkan extensions are:
\begin{itemize}
	\item VK\_KHR\_external\_memory\_capabilities: This extension allow to query to the driver the supported capabilities for external memory resources.
	\item VK\_KHR\_external\_memory: This extension allow to inform the driver that the buffer/image and the associated memory we are going to create could be used with external memory related functions.
	\item VK\_KHR\_external\_memory\_fd: This extension allow to export a Vulkan memory as Linux file descriptor. The supported external memory handle types are:
	\begin{itemize}
		\item Opaque Fd: An opaque handle only known by the driver. The exporting and importing device must match.
	\end{itemize}
	\item VK\_EXT\_external\_memory\_dma\_buf: This extension expand the list of the fd supported external memory handle types with:
	\begin{itemize}
		\item Dma Buf: A direct memory buffer.
	\end{itemize}
	\item VK\_EXT\_image\_drm\_format\_modifier: This extension allow inform the driver about the usage of Linux drm format modifiers to take advantage of special memory layouts. This can be used both when importing an external memory or when creating a memory that will be exported. 
	\item VK\_KHR\_external\_memory\_win32: This extension allow to export a Vulkan memory as Windows handle. The supported external memory handle types are:
	\begin{itemize}
		\item Opaque Win32: An opaque handle only known by the driver. The exporting and importing device must match.
		\item Opaque Win32 Kmt: An opaque handle only known by the driver. The associated Windows handle does not own a reference to the underlying Vulkan memory, so it becomes invalid when the Vulkan memory is deallocated. The exporting and importing device must match.
		\item D3D11 Texture: A d3d11 texture resource. The exporting and importing device must match.
		\item D3D11 Texture Kmt: A d3d11 texture resource. The associated Windows handle does not own a reference to the underlying Vulkan memory, so it becomes invalid when the Vulkan memory is deallocated. The exporting and importing device must match.
		\item D3D12 Heap: A d3d12 heap resource.  The exporting and importing device must match.
		\item D3D12 Resource: A d3d12 committed resource.  The exporting and importing device must match.
	\end{itemize}
	\item VK\_EXT\_external\_memory\_host: This extension allow to export a Vulkan memory as host pointer. The supported external memory handle types are:
	\begin{itemize}
		\item Host allocation: A host pointer. The Vulkan memory will become invalid if the pointer is freed.
		\item Host mapped foreign memory: A host pointer to a host mapped memory. The Vulkan memory will become invalid if the pointer is freed.
	\end{itemize}
\end{itemize}



\section{How a rendering api works}
A modern rendering api like WGpu (the same apply to many other like Vulkan) provides a list of functions that can be used to interact with the underlying driver, and so the gpu. This is by no means a complete overview, it is just an introduction to some concepts that can be used to better understand the following chapters. The main concepts of a rendering api are:
\begin{itemize}
	\item Shader: The shader is little piece of code written with a specialized language designed for highly parallel accelerators, like gpus. It is the only code actually runned by the accelerator.There are many kind of shaders, but for this project, only vertex and fragment shaders are used, so this document will be focusing those.
	\item Resources: There are various resources that can be created like buffers and textures. They can be host allocated (so on the host memory) or device allocated (so on the acceleration device memory). Based on how they are configured and used, they can be read and written in various phases of the rendering
	\item Pipeline: A pipeline define the details of rendering or compute operations. It is the component that glue together parameters, resources, fixed shader stages and programmable shader stages.
	\item Command buffer: A command buffer contains a list of commands that are executed by the accelerator. A command buffer define which commands should be executed and their order, but it do not define details about the operations.
\end{itemize}

\subsection{Vertex shader}
A vertex shader is the first stage of a pipeline and it is used to generate the vertexes of the scene. In this stage, a special buffer called "vertex buffer" can be attached. It will provide data to the shader in a per-instance (so it will change every time a new instance of an object change) or per-vertex basis (so it will change at every drawed vertex).

\newpage
\subsection{Primitive assembly and rasterization stage}
\begin{multicols}{2}
	\vspace*{\fill}
	\centering
	\includegraphics[width=\columnwidth]{primitive_assembly.png}\\
	\captionof{figure}{Primitive assembly stage}\label{pinki}
	\vspace*{\fill}
	\columnbreak
	\vspace*{\fill}
	Vertexes produced by the vertex shader are then pushed into a fixed shader stage called "primitive assembly". Based on the a parameter defined in the rendering pipeline called "primitive topology", the vertexes will be assembled together. Various topology types are available depending on what the device supports and it define how vertexes are combined together to build shapes. Then the produces shapes are passed into another fixed shader stage called "rasterization". In this stage, the shapes are matched against the framebuffer pixel grid (so the pixels that will be then sent to the monitor) and fragments are produced accordingly. Fragments are colorless pixels that will be pushed to the next stage to be further manipulated; they are produced accordingly to the driver (gpu) and the pipeline configuration.
	\vspace*{\fill}
\end{multicols}

\subsection{Fragment shader}
The fragment shader is used to control the color of the fragments and which of them should be discarded. Fragments generally match with an actual pixel on the screen and they are generated automatically based on how the vertexes are assembled and the scene perspective. It is possible to partially control how fragments are generated from the pipeline parameters and it is possible to program the fragment shader stage to discard specific fragments. Fragments that have been elaborated (and keeped) and then sent as output of the fragment stage. Based on the "location" index parameter assigned in the shader, the new pixel is written to the swapchain assigned in the pipeline parameters that has the same defined "location" index. This means that it is also possible to have multiple swapchains and decide inside the shader to which of them the pixels should be written.

\subsection{Command buffer}
Command buffers contain a list of commands that are used to organize how commands are going to be executed on the accelerator. On command buffers can be recorded , for example, the use of resources, pipelines and can be defined dispatching and drawing operations that trigger the actual execution. Many more commands are available and they can be used to manipulate many aspect of the execution. The order those operations are recorded matter and they can be issued multiple times. This means that in the same command buffer multiple draw operation can be defined with different resources or pipelines.
